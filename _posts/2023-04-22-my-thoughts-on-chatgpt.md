---
layout: post
title:  "my thoughts on ChatGPT (a small essay)"
date:   2023-04-22 00:00:00 +0200
categories: tech
---

Artificial intelligence seems to be one of the few technologies of the recent years that has lived up to its hype. Yet, despite years of research and development, it has long been the underdog of the innovation industry. Its applications in the consumer space have been limited mostly to voice assistants, games, and recommendation algorithms. Even the younger generation of entrepreneurs who tried to hype up the public failed. It seemed like there was simply no "killer feature" that would propel it into the hands of millions and make money at the same time. Existing applications were either too limited and focused, or difficult to monetize. Amazon Echo devices equipped with the Alexa voice assistant have millions of users but [can't make money](https://archive.is/pRM5S). As it turns out, even after years on the market, its makers couldn't come up with a viable business model.

But what is interesting about all these applications is that they don't use AI as their main selling point. Its features are appreciated, but the underlying technology is not highlighted. Echo is advertised on a premise that it can play music by voice command and tell how many centimeters are in an inch, not because it is "AI-powered". Yet, when ChatGPT – a generative AI model capable of communicating in the form of a dialog – became available to the general public in late 2022, things changed. Ever since the first screenshots with clever or funny responses circulated on Twitter, ChatGPT has put AI in the spotlight. Since then, reactions have been mixed.

Someone is so scared of the breakneck pace they are calling for a [six-month pause](https://archive.is/MdzlW) on AI research. Yesterday’s “cryptobros”, who shoved blockchain into every possible place, transformed into “AI bros” and proudly slap “AI-powered” on each startup they launch. Some companies, such as Microsoft, already enjoy AI's mass appeal. Those who couldn't pioneer, like Google, are clumsily trying to catch up, making lackluster products (looking at you, [Bard](https://archive.is/yGn2r)) causing [billions of losses](https://archive.is/UD0vA). They seem to be so embarrassed by Bard that even the official website has a blue chip that reads "Experiment". And, while other giants are too busy fighting over the emerging consumer market, companies like Amazon are quietly paving the way for corporate use cases of AI – combining existing models into corporate-friendly packages instead of inventing their own.

But the general population is either indifferent to AI, exploiting it, or terrified of it. The latter category is mostly people whose professions are in the greatest danger, such as artists and writers. Of course, if a product design manager can [publish a 12-page children book alone over the weekend](https://archive.is/vTvhs) – a task that requires many people and several months' worth of work – it makes one wonder whether their artist career is sustainable anymore. And government bodies are also unlikely saviors, at least in the short term since the regulatory response is usually slow and geared towards limiting things. And, considering this, halting AI research may seem like the only viable response.

Yet, the real problem with meaningful AI adoption is treating it like a [black box](https://archive.is/OzUDG). Clarke's third law states: “Any sufficiently advanced technology is indistinguishable from magic”. Understanding how large language models, such as GPT, work dispels their devilry. In the end, they simply produce statistically plausible output for given input. That's why saying they can take someone's job is an overstatement. And, after learning enough, [statements](https://archive.is/TGJoP) about their "sentience" become comical.

Yet, understanding the technology is only the first step. To take AI from the hands of corporate giants and bring its power to the people, standardization, transparency, and community engagement are necessary. Organizations like the Free Software Foundation and Apache Software Foundation have helped to democratize software by creating free and open source software licenses and promoting community-centered development. And today both the private sector and [governments](https://archive.is/jwQrq) enjoy open source software. Even the IT giants themselves have embraced this movement and started contributing. Now the same needs to happen for AI.
